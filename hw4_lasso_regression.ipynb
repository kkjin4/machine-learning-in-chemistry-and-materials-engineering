{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4\n",
    "==========\n",
    "\n",
    "In this homework, we...\n",
    "\n",
    "* extend the zeolite exercise by fitting a multivariable linear regression with Lasso regularization\n",
    "\n",
    "* compare Lasso and Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we apply regularization techniques? Comment on the differences between Ridge and Lasso regularization.\n",
    "\n",
    "<br/>\n",
    "\n",
    "2. We provide standardized data from the zeolite discussion, augmented with random covariates. Fit this data using the following models and report the resulting $R^2$ values. Which model produces the strongest $R^2$?\n",
    "    \n",
    "    - **Hint:** Apply the `LinearRegression`, `Ridge`, and `Lasso` classes in `sklearn.linear_model`.\n",
    "    \n",
    "    - **Another Hint:** `sklearn` uses the `alpha` argument as the regularization parameter, instead of $\\lambda$. In the case of `sklearn.linear_model.Ridge()`, the `alpha` argument is the same as $\\lambda$. In the case of `sklearn.linear_model.Lasso()`, the `alpha` argument should be set to $\\lambda/2$. This is based on how the cost function is defined in the [`sklearn.linear_model.Lasso()` function](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html).\n",
    "\n",
    "    (a) Standard linear regression\n",
    "\n",
    "    (b) Ridge regression ($\\lambda = 1$)\n",
    "\n",
    "    (c) Lasso regression ($\\lambda = 1$)\n",
    "\n",
    "<br/>\n",
    "\n",
    "3. Randomly isolate 50 % of the zeolite examples in what is called the \"training set.\" Assign the remaining 50 % of examples to a \"test set.\" You will learn more about training/test splits during week 5. **For each model** from part 2:\n",
    "\n",
    "    (a) Fit the model to the **training set**\n",
    "\n",
    "    (b) Evaluate $R^2$ of the fitted model on the training data\n",
    "\n",
    "    (c) Apply this fitted model to the testing data, and report the $R^2$\n",
    "\n",
    "    - **Note:** We are expecting six $R^2$ values to be reported for this problem.\n",
    "\n",
    "<br/>\n",
    "\n",
    "4. Let's compare the $R^2$ values we obtain from standard regression and Lasso regression. How do the $R^2$ values of standard and Lasso regression differ for:\n",
    "\n",
    "    (a) the training data\n",
    "\n",
    "    (b) the test data\n",
    "\n",
    "<br/>\n",
    "\n",
    "5. Why could applying Lasso regularization to your regression model cause a change in $R^2$ evaluated on test data?\n",
    "\n",
    "    - **Hint:** You may or may not see this change in $R^2$, depending on the random train/test split that you obtain. Regardless, consider how Lasso regularization affects model generalizability.\n",
    "\n",
    "<br/>\n",
    "\n",
    "6. Re-fit the Lasso regression model from problem 2 on the training set for the following values of $\\lambda$: 0.1, 0.25, 0.5, 0.75, 0.9. Evaluate $R^2$ of each model on the test set. Describe the effect of $\\lambda$ on model generalizability.\n",
    "\n",
    "<br/>\n",
    "\n",
    "7. For each Lasso regression model from problem 6, plot the magnitude of coefficients for the top 20 contributing covariates (i.e., the 20 covariates with the largest magnitude coefficients). How does changing $\\lambda$ affect the magnitude of these top coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and standardize data from: [DFT training set from Evans, Jack D., and Fran√ßois-Xavier Coudert. \"Predicting the mechanical properties of zeolite frameworks by machine learning.\" Chemistry of Materials 29, no. 18 (2017): 7833-7839.]\n",
    "\n",
    "For demonstration purposes, we will add 1000 normally distributed covariates to the data set.\n",
    "These covariates contain no information, and including the covariates in the model is expected to cause overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "data = pd.read_csv(\"data/zeolite_mech.csv\", low_memory = False)\n",
    "covariate_name = ['density', 'spg', 'volume', 'SiOSi_average', 'SiO_average', 'max_dim',\n",
    "                  'largest_free_sphere', 'VolFrac', 'ASA', 'AV']\n",
    "x = np.array(data['g_gbr'])\n",
    "t = np.array(data[covariate_name])\n",
    "\n",
    "# Add normally distributed, random features\n",
    "len_rand_coefs = 1000\n",
    "fake_data = np.random.normal(size=(len(data), len_rand_coefs))\n",
    "t = np.concatenate((t, fake_data), axis=1)\n",
    "fake_coefs = [\"rand_\"+str(i) for i in range(len_rand_coefs)]\n",
    "covariate_name = covariate_name + fake_coefs\n",
    "\n",
    "# Standardize\n",
    "n_e = len(x)\n",
    "n_t = len(t[0,:])\n",
    "t_cen = np.zeros((n_e, n_t))\n",
    "x_cen = (x - np.sum(x) / n_e)\n",
    "x_cen /= np.sqrt(np.sum(x_cen ** 2) / (n_e - 1))\n",
    "for i in range(n_t):\n",
    "    t_cen[:, i] = (t[:, i] - np.sum(t[:, i]) / n_e)\n",
    "    t_cen[:, i] /= np.sqrt(np.sum(t_cen[:, i] ** 2) / (n_e - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we apply regularization techniques? Comment on the differences between Ridge and Lasso regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We provide standardized data from the zeolite discussion, augmented with random covariates. Fit this data using the following models and report the resulting $R^2$ values. Which model produces the strongest $R^2$?\n",
    "    \n",
    "    - **Hint:** Apply the `LinearRegression`, `Ridge`, and `Lasso` classes in `sklearn.linear_model`.\n",
    "    \n",
    "    - **Another Hint:** `sklearn` uses the `alpha` argument as the regularization parameter, instead of $\\lambda$. In the case of `sklearn.linear_model.Ridge()`, the `alpha` argument is the same as $\\lambda$. In the case of `sklearn.linear_model.Lasso()`, the `alpha` argument should be set to $\\lambda/2$. This is based on how the cost function is defined in the [`sklearn.linear_model.Lasso()` function](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html).\n",
    "\n",
    "    (a) Standard linear regression\n",
    "\n",
    "    (b) Ridge regression ($\\lambda = 1$)\n",
    "\n",
    "    (c) Lasso regression ($\\lambda = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Randomly isolate 50 % of the zeolite examples in what is called the \"training set.\" Assign the remaining 50 % of examples to a \"test set.\" You will learn more about training/test splits during week 5. **For each model** from part 2:\n",
    "\n",
    "    (a) Fit the model to the **training set**\n",
    "\n",
    "    (b) Evaluate $R^2$ of the fitted model on the training data\n",
    "\n",
    "    (c) Apply this fitted model to the testing data, and report the $R^2$\n",
    "\n",
    "    - **Note:** We are expecting six $R^2$ values to be reported for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's compare the $R^2$ values we obtain from standard regression and Lasso regression. How do the $R^2$ values of standard and Lasso regression differ for:\n",
    "\n",
    "    (a) the training data\n",
    "\n",
    "    (b) the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Why could applying Lasso regularization to your regression model cause a change in $R^2$ evaluated on test data?\n",
    "\n",
    "    - **Hint:** You may or may not see this change in $R^2$, depending on the random train/test split that you obtain. Regardless, consider how Lasso regularization affects model generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Re-fit the Lasso regression model from problem 2 on the training set for the following values of $\\lambda$: 0.1, 0.25, 0.5, 0.75, 0.9. Evaluate $R^2$ of each model on the test set. Describe the effect of $\\lambda$ on model generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. For each Lasso regression model from problem 6, plot the magnitude of coefficients for the top 20 contributing covariates (i.e., the 20 covariates with the largest magnitude coefficients). How does changing $\\lambda$ affect the magnitude of these top coefficients?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
